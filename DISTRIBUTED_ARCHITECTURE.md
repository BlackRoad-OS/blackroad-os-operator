# Distributed AI Workflow Architecture
## Cloudflare + DigitalOcean + Raspberry Pis + HuggingFace

**Status**: ğŸš€ Ready to Deploy
**Version**: 1.0.0
**Architecture**: Multi-Tier Distributed Edge + Compute

---

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          CLOUDFLARE EDGE (Primary)                          â”‚
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Workers AI Workflows                                                â”‚  â”‚
â”‚  â”‚  - Auto-triage Linear issues                                         â”‚  â”‚
â”‚  â”‚  - Generate Notion docs                                              â”‚  â”‚
â”‚  â”‚  - Content moderation                                                â”‚  â”‚
â”‚  â”‚  - Global edge deployment                                            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                             â”‚
â”‚  Storage:                    AI:                                            â”‚
â”‚  â”œâ”€ KV (workflow state)     â”œâ”€ Workers AI (Llama 3.1)                      â”‚
â”‚  â””â”€ D1 (ledger/history)     â””â”€ HuggingFace API (fallback)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                  â”‚                  â”‚
                    â–¼                  â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DIGITALOCEAN DROPLET  â”‚  â”‚  RASPBERRY PI      â”‚  â”‚  GITHUB + HF        â”‚
â”‚  (Backup + Heavy Lift) â”‚  â”‚  (Distributed AI)  â”‚  â”‚  (Code + Models)    â”‚
â”‚                        â”‚  â”‚                    â”‚  â”‚                     â”‚
â”‚  IP: 159.65.43.12      â”‚  â”‚  IPs:              â”‚  â”‚  Repos: 66          â”‚
â”‚  SSH: shellfish        â”‚  â”‚  - 192.168.4.49    â”‚  â”‚  Models: 15+        â”‚
â”‚                        â”‚  â”‚  - 192.168.4.64    â”‚  â”‚  Orgs: 15           â”‚
â”‚  Runs:                 â”‚  â”‚  - 192.168.4.99    â”‚  â”‚                     â”‚
â”‚  â”œâ”€ FastAPI backup     â”‚  â”‚                    â”‚  â”‚  Auto-deploy:       â”‚
â”‚  â”œâ”€ Heavy AI tasks     â”‚  â”‚  Runs:             â”‚  â”‚  âœ“ Cloudflare       â”‚
â”‚  â”œâ”€ Redundant storage  â”‚  â”‚  â”œâ”€ Local models   â”‚  â”‚  âœ“ Droplet          â”‚
â”‚  â””â”€ Cron jobs          â”‚  â”‚  â”œâ”€ Edge compute   â”‚  â”‚  âœ“ Pi clusters      â”‚
â”‚                        â”‚  â”‚  â””â”€ Data cache     â”‚  â”‚                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Multi-Tier Deployment Strategy

### Tier 1: Edge (Cloudflare Workers)
**Role**: Primary webhook receiver + fast AI processing

**Handles**:
- âœ… Linear webhooks (instant global response)
- âœ… Notion webhooks
- âœ… Quick AI classification (Workers AI)
- âœ… Content moderation
- âœ… State management (KV)
- âœ… Audit trail (D1)

**Benefits**:
- ğŸš€ Sub-50ms response times globally
- ğŸ’° Free tier: 100k requests/day
- ğŸŒ Auto-scaling worldwide
- ğŸ”’ Built-in DDoS protection

### Tier 2: Backup (DigitalOcean Droplet)
**Role**: Redundancy + heavy computation

**IP**: 159.65.43.12
**Access**: SSH via shellfish

**Handles**:
- âœ… Backup of all edge operations
- âœ… Heavy AI tasks (large model inference)
- âœ… Batch processing
- âœ… Database redundancy
- âœ… Cron jobs and scheduled tasks
- âœ… Development/testing environment

**Benefits**:
- ğŸ”§ Full control (root access)
- ğŸ’¾ Persistent storage
- ğŸ”„ Fallback if Cloudflare has issues
- ğŸ“Š Analytics and monitoring

### Tier 3: Distributed Compute (Raspberry Pi Cluster)
**Role**: Local AI processing + data caching

**Nodes**:
- 192.168.4.49 (alice-pi)
- 192.168.4.64 (lucidia.local)
- 192.168.4.99 (lucidia alternate)

**Handles**:
- âœ… Local HuggingFace model hosting
- âœ… Edge AI inference (low latency)
- âœ… Data preprocessing
- âœ… Cache for frequently accessed data
- âœ… Testing new models

**Benefits**:
- ğŸ  Local control, no API costs
- âš¡ Low latency for local requests
- ğŸ”¬ Experimentation friendly
- ğŸ” Private data stays local

### Tier 4: Code & Models (GitHub + HuggingFace)
**Role**: Source of truth for code and AI models

**GitHub**:
- 15 orgs, 66 repos
- Auto-deploy to all tiers
- Single source of truth

**HuggingFace**:
- 15+ models (public + custom)
- Serverless inference
- Model hosting

---

## ğŸ”„ Workflow Routing

### Auto-Triage Flow
```
1. Linear issue created
2. Webhook â†’ Cloudflare Workers (edge)
3. Workers AI classifies (Llama 3.1)
4. Store in KV + D1
5. If P0/P1 â†’ Also send to Droplet backup
6. If custom model needed â†’ Route to Pi cluster
7. Response back to Linear
```

### Notion Doc Generation Flow
```
1. Linear issue marked "Done"
2. Webhook â†’ Cloudflare Workers
3. Workers AI generates feature spec
4. If complex â†’ Offload to Droplet (larger model)
5. Create Notion page via API
6. Store link in KV
7. Update Linear with Notion URL
```

### Content Moderation Flow
```
1. Comment posted in Linear
2. Webhook â†’ Cloudflare Workers
3. Quick moderation check (Workers AI)
4. If flagged â†’ Store in D1 + notify
5. If borderline â†’ Send to Droplet for deep analysis
```

---

## ğŸš€ Deployment Steps

### Step 1: Deploy Cloudflare Workers (Edge)

```bash
cd workers/ai-workflows

# Install dependencies
npm install

# Create D1 database
wrangler d1 create ai-workflows-ledger

# Update wrangler.toml with database ID

# Initialize database schema
wrangler d1 execute ai-workflows-ledger --file=schema.sql

# Create KV namespace
wrangler kv:namespace create WORKFLOW_STATE

# Set secrets
wrangler secret put LINEAR_API_KEY
wrangler secret put NOTION_API_KEY
wrangler secret put HUGGINGFACE_API_KEY

# Deploy!
wrangler deploy
```

**URL**: `https://ai-workflows.blackroad.systems`

### Step 2: Setup DigitalOcean Droplet (Backup)

```bash
# SSH to droplet (via shellfish)
ssh root@159.65.43.12

# Clone operator repo
git clone https://github.com/BlackRoad-OS/blackroad-os-operator.git
cd blackroad-os-operator

# Install dependencies
pip install -r requirements.txt

# Set environment variables
export LINEAR_API_KEY="..."
export NOTION_API_KEY="..."
export HUGGINGFACE_API_KEY="..."

# Run operator (systemd or Docker)
uvicorn br_operator.main:app --host 0.0.0.0 --port 8080

# Setup reverse proxy (nginx)
# Point: operator.blackroad.systems â†’ 159.65.43.12:8080
```

**URL**: `https://operator.blackroad.systems` (backup)

### Step 3: Configure Raspberry Pi Cluster

```bash
# SSH to each Pi
ssh pi@192.168.4.49  # alice-pi
ssh pi@192.168.4.64  # lucidia
ssh pi@192.168.4.99  # lucidia-alt

# On each Pi:
# Install HuggingFace transformers
pip3 install transformers torch

# Download models locally
python3 -c "from transformers import AutoModel; AutoModel.from_pretrained('facebook/bart-large-cnn')"

# Run local inference server
python3 -m http.server 8000  # Simple example

# Configure health check cron
echo "*/5 * * * * curl https://ai-workflows.blackroad.systems/health" | crontab -
```

### Step 4: Configure Linear Webhook

```bash
Linear â†’ Settings â†’ Webhooks
URL: https://ai-workflows.blackroad.systems/webhooks/linear
Events: âœ“ Issue created, âœ“ Issue updated, âœ“ Comment created
```

### Step 5: Configure Notion Integration

```bash
Notion â†’ Settings â†’ Integrations â†’ New Integration
Name: BlackRoad AI Workflows
Capabilities: âœ“ Read content, âœ“ Insert content, âœ“ Update content

Copy integration secret â†’ wrangler secret put NOTION_API_KEY
```

---

## ğŸ“Š Infrastructure Health Monitoring

### Cloudflare Workers Dashboard
```bash
# View real-time logs
wrangler tail

# Check analytics
wrangler pages deployment list
```

### DigitalOcean Monitoring
```bash
# Check service status
ssh root@159.65.43.12 "systemctl status operator"

# View logs
ssh root@159.65.43.12 "tail -f /var/log/operator.log"
```

### Raspberry Pi Health
```bash
# Check all Pis
for ip in 192.168.4.49 192.168.4.64 192.168.4.99; do
  echo "=== $ip ==="
  ssh pi@$ip "uptime && df -h"
done
```

### Unified Health Check
```bash
# Check all infrastructure
curl https://ai-workflows.blackroad.systems/health

# Expected response:
{
  "edge": "online",
  "backup": "online",
  "pi_cluster": {
    "192.168.4.49": "online",
    "192.168.4.64": "online",
    "192.168.4.99": "online"
  },
  "ai_providers": {
    "workers_ai": "online",
    "huggingface": "online"
  }
}
```

---

## ğŸ” Secrets Management

### Cloudflare Workers (wrangler secret)
```bash
wrangler secret put LINEAR_API_KEY
wrangler secret put NOTION_API_KEY
wrangler secret put HUGGINGFACE_API_KEY
wrangler secret put DIGITALOCEAN_SSH_KEY  # For droplet orchestration
```

### DigitalOcean Droplet (environment variables)
```bash
# Add to ~/.bashrc or /etc/environment
export LINEAR_API_KEY="..."
export NOTION_API_KEY="..."
export HUGGINGFACE_API_KEY="..."
```

### Raspberry Pi (local config)
```bash
# Store in /home/pi/.env
LINEAR_API_KEY="..."
NOTION_API_KEY="..."
EDGE_ENDPOINT="https://ai-workflows.blackroad.systems"
```

---

## ğŸ¯ Cost Breakdown

| Service | Tier | Cost/Month | Usage |
|---------|------|------------|-------|
| Cloudflare Workers | Free | $0 | 100k req/day |
| Cloudflare Workers AI | Free | $0 | 10k req/day |
| Cloudflare KV | Free | $0 | 1GB storage |
| Cloudflare D1 | Free | $0 | 5GB storage |
| DigitalOcean Droplet | Basic | $6 | Backup + heavy compute |
| Raspberry Pis | One-time | $0* | Local compute |
| HuggingFace Inference | Free | $0 | 1000 req/hr |
| GitHub | Free | $0 | Public repos |
| **Total** | | **$6/month** | |

*Already owned hardware

---

## ğŸš€ Next Steps

1. âœ… Deploy Cloudflare Workers
2. âœ… Wake up DigitalOcean droplet
3. âœ… Configure Raspberry Pis
4. âœ… Test end-to-end workflow
5. âœ… Monitor and optimize

---

## ğŸ“š Documentation

- **Cloudflare Workers**: [workers/ai-workflows/README.md](#)
- **DigitalOcean Setup**: [docs/DIGITALOCEAN_SETUP.md](#)
- **Raspberry Pi Config**: [docs/RASPBERRY_PI_SETUP.md](#)
- **API Reference**: [docs/AI_WORKFLOWS_INTEGRATION.md](./docs/AI_WORKFLOWS_INTEGRATION.md)

---

**Built with love by**: Claude + Alexa
**Infrastructure**: Cloudflare + DigitalOcean + Raspberry Pi + GitHub + HuggingFace
**Status**: Ready to take over the world ğŸŒğŸš€
